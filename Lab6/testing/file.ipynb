{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4vV79FzYN5P7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pfgO8V6qj3Y2"
   },
   "outputs": [],
   "source": [
    "train_file = \"leaf_village_train2.csv\"\n",
    "validation_file = \"leaf_village_validation2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s68l7p5xNV2e"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_file)\n",
    "validation_data = pd.read_csv(validation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Sh5tEV7TOCKG",
    "outputId": "6984df99-5db4-4ac6-c465-a3344ca97ba1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is the nearest ramen shop?</td>\n",
       "      <td>Ichiraku Ramen, near Market Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you guide me to the training grounds?</td>\n",
       "      <td>Take the path behind the academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the quickest route to the Hokage Rock?</td>\n",
       "      <td>Head north from the village square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How far is the Ninja Academy from here?</td>\n",
       "      <td>About a 5 minute walk from the gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where can I find the Anbu headquarters?</td>\n",
       "      <td>Near the village outskirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Are there recreational spaces?</td>\n",
       "      <td>Yes, near the training grounds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Where can I read about Leaf Village history?</td>\n",
       "      <td>At the library.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Is there a gym in the village?</td>\n",
       "      <td>Yes, at the training grounds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Are there places to meditate?</td>\n",
       "      <td>Yes, near the Hyuga Compound.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Are there music lessons in the village?</td>\n",
       "      <td>Yes, near the square.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "0                 Where is the nearest ramen shop?   \n",
       "1        Can you guide me to the training grounds?   \n",
       "2   What is the quickest route to the Hokage Rock?   \n",
       "3          How far is the Ninja Academy from here?   \n",
       "4          Where can I find the Anbu headquarters?   \n",
       "..                                             ...   \n",
       "59                  Are there recreational spaces?   \n",
       "60    Where can I read about Leaf Village history?   \n",
       "61                  Is there a gym in the village?   \n",
       "62                   Are there places to meditate?   \n",
       "63         Are there music lessons in the village?   \n",
       "\n",
       "                                 answer  \n",
       "0    Ichiraku Ramen, near Market Street  \n",
       "1      Take the path behind the academy  \n",
       "2    Head north from the village square  \n",
       "3   About a 5 minute walk from the gate  \n",
       "4            Near the village outskirts  \n",
       "..                                  ...  \n",
       "59      Yes, near the training grounds.  \n",
       "60                      At the library.  \n",
       "61        Yes, at the training grounds.  \n",
       "62        Yes, near the Hyuga Compound.  \n",
       "63                Yes, near the square.  \n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-y4pSdvLN7P4"
   },
   "outputs": [],
   "source": [
    "# Load SpaCy tokenizer\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tokenizer function\n",
    "def tokenize(text):\n",
    "    return [token.text.lower() for token in spacy_en.tokenizer(text) if not token.is_punct]\n",
    "\n",
    "\n",
    "# Special tokens\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "START_TOKEN = \"<start>\"\n",
    "END_TOKEN = \"<end>\"\n",
    "UNK_TOKEN = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VI_esuP9N-l5"
   },
   "outputs": [],
   "source": [
    "# Vocabulary creation\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.word2idx[PAD_TOKEN] = 0\n",
    "        self.word2idx[START_TOKEN] = 1\n",
    "        self.word2idx[END_TOKEN] = 2\n",
    "        self.word2idx[UNK_TOKEN] = 3\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def build_vocab(self, tokenized_texts, max_size=10000, min_freq=1):\n",
    "        for tokens in tokenized_texts:\n",
    "            self.counter.update(tokens)\n",
    "        for word, freq in self.counter.items():\n",
    "            if freq >= min_freq and word.isalnum() and len(self.word2idx) < max_size:\n",
    "                idx = len(self.word2idx)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2_mLlxuqOBV6"
   },
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, csv_file, question_vocab, answer_vocab):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.question_vocab = question_vocab\n",
    "        self.answer_vocab = answer_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = tokenize(self.data.iloc[idx, 0])  # Tokenize question\n",
    "        answer = tokenize(self.data.iloc[idx, 1])  # Tokenize answer\n",
    "\n",
    "        # Convert to integer sequences\n",
    "        question_seq = [self.question_vocab.word2idx.get(w, self.question_vocab.word2idx[UNK_TOKEN]) for w in question]\n",
    "        answer_seq = [self.answer_vocab.word2idx.get(w, self.answer_vocab.word2idx[UNK_TOKEN]) for w in answer]\n",
    "\n",
    "        # Add special tokens\n",
    "        question_seq = [self.question_vocab.word2idx[START_TOKEN]] + question_seq + [self.question_vocab.word2idx[END_TOKEN]]\n",
    "        answer_seq = [self.answer_vocab.word2idx[START_TOKEN]] + answer_seq + [self.answer_vocab.word2idx[END_TOKEN]]\n",
    "\n",
    "        return torch.tensor(question_seq), torch.tensor(answer_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Bzpz2dhZOEBB"
   },
   "outputs": [],
   "source": [
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    questions, answers = zip(*batch)\n",
    "    questions = torch.nn.utils.rnn.pad_sequence(questions, batch_first=True, padding_value=0)\n",
    "    answers = torch.nn.utils.rnn.pad_sequence(answers, batch_first=True, padding_value=0)\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rfJ3l73Db5Ts"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_csv, val_csv):\n",
    "    # Load CSV files into pandas DataFrames\n",
    "    train_data = pd.read_csv(train_csv)\n",
    "    val_data = pd.read_csv(val_csv)\n",
    "\n",
    "    # Tokenize all data\n",
    "    train_questions = [tokenize(q) for q in train_data['question']]\n",
    "    train_answers = [tokenize(a) for a in train_data['answer']]\n",
    "    val_questions = [tokenize(q) for q in val_data['question']]\n",
    "    val_answers = [tokenize(a) for a in val_data['answer']]\n",
    "\n",
    "    # Build vocabularies\n",
    "    question_vocab = Vocabulary()\n",
    "    answer_vocab = Vocabulary()\n",
    "    question_vocab.build_vocab(train_questions)\n",
    "    answer_vocab.build_vocab(train_answers)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = QADataset(train_csv, question_vocab, answer_vocab)\n",
    "    val_dataset = QADataset(val_csv, question_vocab, answer_vocab)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader, question_vocab, answer_vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uHlf6yrMOVJm"
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, question_vocab, answer_vocab = preprocess_data(\n",
    "    \"leaf_village_train2.csv\",\n",
    "    \"leaf_village_validation2.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9sIUSMhQ6TU",
    "outputId": "b04a3000-717e-4aa0-a8fd-48243a555dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions batch: tensor([[  1,  47,  32, 153,  50, 154,   2,   0,   0,   0,   0,   0],\n",
      "        [  1, 145,  36,  28, 146, 147, 148,  14,   2,   0,   0,   0],\n",
      "        [  1,  10,  28,  97,  33,  15,  98,   2,   0,   0,   0,   0],\n",
      "        [  1,  22,  36,  28,  37, 113,   6,  46,   2,   0,   0,   0],\n",
      "        [  1,  17,  47,   6,  69,  70,  44,   6,  45,  46,   2,   0],\n",
      "        [  1,   4,   5,   6,   7,   8,   9,   2,   0,   0,   0,   0],\n",
      "        [  1,   5,  32,  33, 165,  44,   6,  46,   2,   0,   0,   0],\n",
      "        [  1,   4,  10,  28,  29,  33,  57,   2,   0,   0,   0,   0],\n",
      "        [  1,   4,  10,  28,  29,  96,  44,   6,  45,  46,   2,   0],\n",
      "        [  1,  47,  32, 107, 108,   2,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  47,  32, 104, 105,  50, 106,   2,   0,   0,   0,   0],\n",
      "        [  1,  47,  32,  48,  99, 100, 101,   2,   0,   0,   0,   0],\n",
      "        [  1,  47,  32,  59,  44,   6,  45,  46,   2,   0,   0,   0],\n",
      "        [  1,  17,   3,   6,  79,  80,  50,  81,  44,   6,  46,   2],\n",
      "        [  1,  47,  32, 161, 162,   2,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   4,   5,   6,  40,  14,   6,  41,  42,  43,   2,   0],\n",
      "        [  1,  10,  28,  29,  88,  44,   6,  46,   2,   0,   0,   0],\n",
      "        [  1,  47,  32,  87,  49,  44,   6,  46,   2,   0,   0,   0],\n",
      "        [  1,  47,  32,  48,  49,  50,  24,  51,  52,   2,   0,   0],\n",
      "        [  1,   4,  10,  28,  29,  33, 158,   2,   0,   0,   0,   0],\n",
      "        [  1,  47,  32, 166,  14, 167,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  10,  28,  65, 112,  68,  27,   2,   0,   0,   0,   0],\n",
      "        [  1,   5,  32,  33,  71,  42,   6,  20,   3,  72,   2,   0],\n",
      "        [  1,   4,  10,  28,  86,   8,  44,   6,  45,  46,   2,   0],\n",
      "        [  1,   5,  32,  33, 128, 129, 130,   2,   0,   0,   0,   0],\n",
      "        [  1,  47,  32, 114, 115,  44,   6,  45,  46,   2,   0,   0],\n",
      "        [  1,  10,  11,  12,  13,  14,   6,  15,  16,   2,   0,   0],\n",
      "        [  1,  22, 116, 117, 118, 119,  14, 120,   6,  46,   2,   0],\n",
      "        [  1,   5,  32,  33,  75,  92,  50,  64,   2,   0,   0,   0],\n",
      "        [  1,   5,  32,  33,  62,  50,  63,  64,   2,   0,   0,   0],\n",
      "        [  1,  47,  32,  76,  44,   6,  45,  46,   2,   0,   0,   0],\n",
      "        [  1,  10,  28, 126,  33,  12,  50, 127,   2,   0,   0,   0]])\n",
      "Answers batch: tensor([[  1,  26,  36,  10,  32,  33,   2,   0,   0],\n",
      "        [  1,  10,  38,  39,   2,   0,   0,   0,   0],\n",
      "        [  1,  26,  51,  52,   2,   0,   0,   0,   0],\n",
      "        [  1,  23,  75,  77,  78,   2,   0,   0,   0],\n",
      "        [  1,  48,  49,  50,   4,   5,   2,   0,   0],\n",
      "        [  1,   4,   5,   6,   7,   8,   2,   0,   0],\n",
      "        [  1,  26,  36,  10,  32,  33,   2,   0,   0],\n",
      "        [  1,   6,  10,  32,  33,  40,  41,   8,   2],\n",
      "        [  1,  36,  10,  65,  46,   2,   0,   0,   0],\n",
      "        [  1,  26,  36,  10,  74,   2,   0,   0,   0],\n",
      "        [  1,  26,  73,  36,  10,  30,  24,   2,   0],\n",
      "        [  1,  26,  69,  70,  71,  72,   2,   0,   0],\n",
      "        [  1,  26,  44,  10,  18,   2,   0,   0,   0],\n",
      "        [  1,  48,  49,  36,  57,   2,   0,   0,   0],\n",
      "        [  1,  26,   6,  10,  32,  33,   2,   0,   0],\n",
      "        [  1,   6,  10,  31,  32,  33,   2,   0,   0],\n",
      "        [  1,  26,  36,  61,   3,  46,   2,   0,   0],\n",
      "        [  1,  26,  36,  10,   7,  18,   2,   0,   0],\n",
      "        [  1,  26,  36,  10,  37,   7,   2,   0,   0],\n",
      "        [  1,  36,  10,  97,  75,  32,  33,   2,   0],\n",
      "        [  1,  26,   6,  10,  99, 100,   2,   0,   0],\n",
      "        [  1,  26,  16,  10,  13,  75,  76,   2,   0],\n",
      "        [  1,  26,  51,  52,   2,   0,   0,   0,   0],\n",
      "        [  1,   4,   5,   6,   7,   8,   2,   0,   0],\n",
      "        [  1,  79,  80,  89,  90,  91,  92,   2,   0],\n",
      "        [  1,  79,  80,  81,  82,  83,   2,   0,   0],\n",
      "        [  1,   9,  10,  11,  12,  10,  13,   2,   0],\n",
      "        [  1,  19,  84,  85,   2,   0,   0,   0,   0],\n",
      "        [  1,  26,  66,  67,  68,   2,   0,   0,   0],\n",
      "        [  1,  26,  10,  43,  13,   2,   0,   0,   0],\n",
      "        [  1,  26,  10,  54,  55,   2,   0,   0,   0],\n",
      "        [  1,  26,  16,  10,  38,  39,   2,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "for questions, answers in train_loader:\n",
    "    print(\"Questions batch:\", questions)\n",
    "    print(\"Answers batch:\", answers)\n",
    "    break  # Check the first batch only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h0HEuiegQ_rJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, num_layers, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)  # Outputs ignored; focus on hidden and cell\n",
    "        return hidden, cell  # (num_layers, batch_size, hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cLoTTfchSTul"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, num_layers, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x: (batch_size) -> Need to reshape to (batch_size, 1)\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.embedding(x)  # (batch_size, 1, embed_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc(outputs.squeeze(1))  # (batch_size, output_dim)\n",
    "        return predictions, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7HnQuwJPSUXq"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        trg_vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        # First input to the decoder is the <start> token\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            top1 = output.argmax(1)  # Get the highest probability token\n",
    "            input = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vZ9nOdUlSaRY"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "INPUT_DIM = len(question_vocab.word2idx)\n",
    "OUTPUT_DIM = len(answer_vocab.word2idx)\n",
    "EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Qu9gfObXScic"
   },
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = Encoder(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore <pad> token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XAs34BvpSWgD"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, trg in iterator:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)  # (batch_size, trg_len, trg_vocab_size)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in iterator:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, 0)  # Turn off teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QH_jSuz4Sgc4"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, n_epochs, clip):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Training\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, clip)\n",
    "\n",
    "        # Validation\n",
    "        val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        print(f'Epoch {epoch:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFGRKnHMSn4d",
    "outputId": "93a7000d-a45e-4de1-da68-7812743e3444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.494 | Val Loss: 3.356\n",
      "Epoch 02 | Train Loss: 1.384 | Val Loss: 3.394\n",
      "Epoch 03 | Train Loss: 1.379 | Val Loss: 3.342\n",
      "Epoch 04 | Train Loss: 1.217 | Val Loss: 3.498\n",
      "Epoch 05 | Train Loss: 1.235 | Val Loss: 3.471\n",
      "Epoch 06 | Train Loss: 1.091 | Val Loss: 3.687\n",
      "Epoch 07 | Train Loss: 1.117 | Val Loss: 3.565\n",
      "Epoch 08 | Train Loss: 0.974 | Val Loss: 3.598\n",
      "Epoch 09 | Train Loss: 0.956 | Val Loss: 3.867\n",
      "Epoch 10 | Train Loss: 0.853 | Val Loss: 3.862\n",
      "Epoch 11 | Train Loss: 0.773 | Val Loss: 3.883\n",
      "Epoch 12 | Train Loss: 0.748 | Val Loss: 3.903\n",
      "Epoch 13 | Train Loss: 0.639 | Val Loss: 4.058\n",
      "Epoch 14 | Train Loss: 0.635 | Val Loss: 4.084\n",
      "Epoch 15 | Train Loss: 0.570 | Val Loss: 4.206\n",
      "Epoch 16 | Train Loss: 0.524 | Val Loss: 4.312\n",
      "Epoch 17 | Train Loss: 0.493 | Val Loss: 4.195\n",
      "Epoch 18 | Train Loss: 0.432 | Val Loss: 4.302\n",
      "Epoch 19 | Train Loss: 0.406 | Val Loss: 4.457\n",
      "Epoch 20 | Train Loss: 0.347 | Val Loss: 4.369\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, N_EPOCHS, CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyDVJWdfS29g",
    "outputId": "282cf473-07dc-4c4a-c737-f3fac5c9d870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Perplexity: 78.96\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_perplexity(loss):\n",
    "    return math.exp(loss)\n",
    "\n",
    "# Example usage\n",
    "val_loss = evaluate(model, val_loader, criterion)\n",
    "perplexity = calculate_perplexity(val_loss)\n",
    "print(f\"Validation Perplexity: {perplexity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "LONL77CqTRUT"
   },
   "outputs": [],
   "source": [
    "def test_model(model, question, question_vocab, answer_vocab, max_len=20):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and numericalize the question\n",
    "    tokens = [question_vocab.word2idx.get(word, question_vocab.word2idx[\"<unk>\"]) for word in tokenize(question)]\n",
    "    tokens = [question_vocab.word2idx[\"<start>\"]] + tokens + [question_vocab.word2idx[\"<end>\"]]\n",
    "    src = torch.tensor(tokens).unsqueeze(0).to(device)  # (1, seq_len)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src)\n",
    "\n",
    "        # Start decoding\n",
    "        trg_indices = [answer_vocab.word2idx[\"<start>\"]]\n",
    "        for _ in range(max_len):\n",
    "            trg_tensor = torch.tensor([trg_indices[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "            pred_token = output.argmax(1).item()\n",
    "            trg_indices.append(pred_token)\n",
    "\n",
    "            if pred_token == answer_vocab.word2idx[\"<end>\"]:\n",
    "                break\n",
    "\n",
    "    # Convert indices back to words\n",
    "    trg_tokens = [answer_vocab.idx2word[idx] for idx in trg_indices]\n",
    "    return \" \".join(trg_tokens[1:-1])  # Remove <start> and <end>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXSJsNDcTk0A",
    "outputId": "7be44409-1582-4a22-e30c-229aa6c690c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Where is the nearest ramen shop?\n",
      "A: ichiraku ramen near market street\n",
      "\n",
      "Q: Where can I see the Hokage Monument?\n",
      "A: about hokage rock\n",
      "\n",
      "Q: Are there festivals in the Leaf Village?\n",
      "A: yes the fire festival\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unseen questions\n",
    "test_questions = [\n",
    "    \"Where is the nearest ramen shop?\",\n",
    "    \"Where can I see the Hokage Monument?\",\n",
    "    \"Are there festivals in the Leaf Village?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    answer = test_model(model, question, question_vocab, answer_vocab)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "torch.save(model.state_dict(), \"seq2seq.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
